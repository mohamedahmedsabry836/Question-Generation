# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15XXrXWVrPUOdu2EI1hZd94JSATlUk7Fz
"""

!pip install bert_score

!pip install evaluate

import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
from nltk.probability import FreqDist
from transformers import pipeline
from datasets import load_dataset
import pandas as pd
import re
import logging
import evaluate
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')

"""Question Generation

> Add blockquote


"""

logging.getLogger("transformers").setLevel(logging.ERROR)

dataset = load_dataset("squad", split="train[:2%]")

small_dataset = dataset.select(range(20))

"""preprocessing

"""

def preprocess_text(text):
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    sentences = sent_tokenize(text)
    stop_words = set(stopwords.words('english'))
    filtered_words = [w.lower() for w in word_tokenize(text) if w.lower() not in stop_words]
    return sentences, filtered_words

def extract_keywords(filtered_words, top_n=5):
    fdist = FreqDist(filtered_words)
    return [word for word, freq in fdist.most_common(top_n)]

generator = pipeline("text2text-generation", model="t5-small", device=-1)

def generate_questions(context, keywords, model_name="t5-small"):
    generator = pipeline("text2text-generation", model=model_name)
    questions = []
    for keyword in keywords:
        prompt = f"Generate a question based on the keyword '{keyword}' in the following context: {context}"
        result = generator(prompt, max_new_tokens=100, num_return_sequences=1)
        questions.append({
            "Keyword": keyword,
            "Question": result[0]['generated_text'],
            "Answer": keyword,
            "Context": context
        })
    return questions

generator = pipeline("text2text-generation", model="t5-small", device=0)
all_results = []
for example in dataset:
    context = example["context"]
    answer = example["answers"]["text"][0] if example["answers"]["text"] else None
    sentences, filtered_words = preprocess_text(context)
    keywords = extract_keywords(filtered_words, top_n=1)
    qas = generate_questions(context, keywords)

    for qa in qas:
        qa["Answer"] = answer if answer else qa["Answer"]
        all_results.append(qa)

df = pd.DataFrame(all_results)
df.to_csv("generated_questions.csv", index=False, encoding="utf-8")

"""Evalution

"""

references = []
predictions = []

for example, qa in zip(dataset, all_results):
    ref_question = example["question"]
    gen_question = qa["Question"]

    references.append(ref_question)
    predictions.append(gen_question)

# 1. BLEU
bleu = evaluate.load("bleu")
bleu_score = bleu.compute(predictions=predictions, references=[[ref] for ref in references])

# 3. BERTScore
bertscore = evaluate.load("bertscore")
bertscore_score = bertscore.compute(predictions=predictions, references=references, lang="en")

print(f"BLEU Score: {bleu_score['bleu']:.4f}")
print(f"BERTScore (F1): {sum(bertscore_score['f1'])/len(bertscore_score['f1']):.4f}")

!pip install streamlit

import streamlit as st
from transformers import pipeline

# generator = pipeline("text2text-generation", model="t5-small", device=-1)

# st.title("Simple Multi-Question Generator")

# user_text = st.text_area("Enter some text:")

# num_questions = st.slider("Number of questions", min_value=1, max_value=5, value=3)

# if st.button("Generate Questions"):
#     if user_text.strip():
#         st.write("### Generated Questions:")
#         for i in range(num_questions):
#             prompt = f"Generate a question from: {user_text}"
#             result = generator(prompt, max_new_tokens=50, num_return_sequences=1)
#             st.success(result[0]['generated_text'])
#     else:
#         st.warning("Please enter some text.")